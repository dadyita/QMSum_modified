professor e: Let 's see . Test ? Test ? Yeah . OK . grad a: Hello ? phd b: Channel one . grad a: Hello ? phd c: Test . professor e: I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go . phd f: OK . professor e: Um . So other than reading digits , what 's our agenda ? phd f: I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So . professor e: OK . Um . Do you think that would be the case for next week also ? Or is {disfmarker} is , uh {disfmarker} ? What 's your projection on {disfmarker} ? phd f: Um . professor e: Cuz the one thing {disfmarker} the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me {disfmarker} it was sort of an obvious thing {disfmarker} is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff . phd f: I did play with that , actually , a little bit . Um . What happens is , uh , {vocalsound} when you get to the noisy stuff , you start getting lots of insertions . professor e: Right . phd f: And , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that . professor e: Yeah . phd f: Um . I mean , it {disfmarker} it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um . {vocalsound} I could do more playing with that , though . And , uh {disfmarker} professor e: But you were looking at mel cepstrum . phd f: and see . Yes . professor e: Right . phd f: Oh , you 're talking about for th {vocalsound} for our features . professor e: Right . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the {disfmarker} uh , what 's the best you can do with {disfmarker} with mel cepstrum . But , they raised a very valid point , phd f: Mmm . professor e: which , I guess {disfmarker} So , to first order {disfmarker} I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @ {comment} with , uh , you know , how many states and so forth , that it {disfmarker} it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians , phd f: Right . professor e: but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ? phd f: Mm - hmm . professor e: Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would . phd f: Yeah . professor e: So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum . phd f: Mm - hmm . professor e: But , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with {disfmarker} with LDA and KLT and neural nets and {vocalsound} all these things . In the fa past we 've always found that we had to increase the insertion penalty to {disfmarker} to correspond to such things . So , I think that 's , uh , @ @ {comment} that 's kind of a first - order thing that {disfmarker} that we should try . phd f: So for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes professor e: So by " our front - end " I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something . phd f: if we were {disfmarker} Mm - hmm . professor e: Um . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How {disfmarker} how much , uh , does it improve if you actually adjust that ? phd f: OK . professor e: But it is interesting . You say you {disfmarker} you have for the noisy {disfmarker} How about for the {disfmarker} for the mismatched or {disfmarker} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ? phd f: Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case . professor e: Yeah . phd f: Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone . professor e: Yeah . phd f: Um , but , uh , that {disfmarker} that 's all I wrote down . professor e: OK . phd f: So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that . professor e: OK . So {disfmarker} phd f: I can do that for next week . professor e: Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that . phd f: OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you phd b: Hmm . phd f: or you point me to some files {pause} that you 've already calculated . phd b: Yeah . Alright . professor e: OK . Uh . phd f: I probably will have time to do that and time to play a little bit with the silence model . professor e: Mm - hmm . phd f: So maybe I can have that for next week when Hynek 's here . professor e: Yeah . phd b: Mm - hmm . professor e: Yeah . Cuz , I mean , the {disfmarker} the other {disfmarker} That , in fact , might have been part of what , uh , the difference was {disfmarker} at least part of it that {disfmarker} that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system . phd f: Hmm . professor e: Part of it might just be that the SRI system , they {disfmarker} they {disfmarker} they always adjust these things to be sort of optimized , phd f: Is there {disfmarker} ? professor e: and {disfmarker} phd f: I wonder if there 's anything that we could do {vocalsound} to the front - end that would affect the insertion {disfmarker} professor e: Yes . I think you can . phd f: What could you do ? professor e: Well , um {disfmarker} uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root . phd f: Oh . Mm - hmm . professor e: You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven . phd f: Mm - hmm . professor e: But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model phd f: Oh , right . professor e: as opposed to what 's coming from the language model . phd f: So that w Right . So , in effect , that 's changing the value of your insertion penalty . professor e: Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling , phd f: That 's interesting . professor e: but you know that those things have kind of a similar effect to the insertion penalty phd f: Mm - hmm . professor e: anyway . They 're a slightly different way of {disfmarker} of handling it . phd f: Right . professor e: So , um {disfmarker} phd f: So if we know what the insertion penalty is , then we can get an idea about what range our number should be in , professor e: I think so . phd f: so that they {pause} match with that . professor e: Yeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing {disfmarker} ? Y y phd f: Mm - hmm . professor e: I 'm sure you 've already looked at this bu in these noisy cases , are {disfmarker} ? We are seeing lots of insertions . Right ? The insertion number is quite high ? phd b: Yeah . professor e: I know the VAD takes pre care of part of that , phd f: Yeah . phd b: Yeah . professor e: but {disfmarker} phd f: I 've seen that with the mel cepstrum . I don't {disfmarker} I don't know about {pause} the Aurora front - end , but {disfmarker} phd b: I think it 's much more balanced with , uh {disfmarker} when the front - end is more robust . Yeah . I could look at it {disfmarker} at this . Yeah . Mm - hmm . professor e: Yeah . Wha - what 's a typical number ? phd b: I don't {disfmarker} I don't know . professor e: Do we {disfmarker} ? Oh , you {disfmarker} oh , you don't know . phd b: I don't have this in {disfmarker} professor e: OK . I 'm sure it 's more balanced , phd b: Mm - hmm . professor e: but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker} phd b: Mm - hmm . professor e: I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions . phd b: Mm - hmm . phd f: Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker} professor e: Right . phd f: that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So . phd b: Mmm . professor e: Right . phd f: I 'll bet you there 's still a lot {vocalsound} of insertions . phd b: Mm - hmm . professor e: Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range . phd f: Mm - hmm . professor e: So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range . phd f: Right . professor e: But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that , phd f: Mm - hmm . professor e: uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what these {disfmarker} these penalties and scaling factors are , you reach some point that 's a {disfmarker} that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we {disfmarker} if we see {disfmarker} Um , I mean we ca it 's if we actually could pick a {disfmarker} a {disfmarker} a more stable value for the range of these features , it , um , uh , could {disfmarker} Uh {disfmarker} Even though it 's {disfmarker} it 's {disfmarker} it 's true that in a real situation you can in fact adjust the {disfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range {disfmarker} phd f: Hmm . professor e: I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a {disfmarker} phd f: Mm - hmm . professor e: for an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and {disfmarker} Uh , we might just not even be in the right operating range . phd f: So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ? professor e: No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker} phd f: Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker} professor e: Yeah . phd f: we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to {disfmarker} to map everything into ? professor e: Well . It depends how much we wanna do gamesmanship and how much we wanna do {disfmarker} I mean , i if he it {disfmarker} to me , actually , even if you wanna be {disfmarker} play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the {disfmarker} set the scaling factors , uh , so that you got the best number for this point four five times the {disfmarker} {vocalsound} you know , and so on . phd f: Mm - hmm . professor e: But they might change that {disfmarker} those weightings . phd f: Yeah . professor e: Um . So {disfmarker} Uh {disfmarker} I just sorta think we need to explore the space . Just take a look at it a little bit . phd f: Mm - hmm . professor e: And we {disfmarker} we {disfmarker} we may just find that {disfmarker} that we 're way off . phd f: OK . Mm - hmm . professor e: Maybe we 're not . You know ? As for these other things , it may turn out that , uh , {vocalsound} it 's kind of reasonable . But then {disfmarker} I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future {disfmarker} of , you know , people {disfmarker} people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say " Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end , phd f: Yeah . professor e: when all you could do is just adjust this in the back - end with one s one knob . " phd f: Mm - hmm . professor e: And so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with {disfmarker} with what we 're doing . And as you say {disfmarker} as you point out {disfmarker} finding ways to then compensate for that in the front - end {vocalsound} also then becomes a priority for this particular test , phd f: Right . professor e: and saying you don't have to do that . phd f: Mm - hmm . professor e: So . OK . So , uh {disfmarker} What 's new with you ? phd b: Uh . So there 's nothing {pause} new . Um . professor e: Uh , what 's old with you that 's developed ? phd b: I 'm sorry ? professor e: You {disfmarker} OK . What 's old with you that has developed over the last week or two ? phd b: Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah . phd f: Mainly working on what ? phd b: On the report {pause} of the work that was already done . phd f: Oh . phd b: Um . Mm - hmm . That 's all . phd f: How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ? phd c: I don't have results yet . phd f: No results ? Yeah . professor e: What was that ? phd f: The {disfmarker} the , uh , grad a: Voicing thing . phd f: voicing detector . professor e: I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ? phd c: Uh , to try to found , nnn , robust feature for detect between voice and unvoice . And we {disfmarker} w we try to use {vocalsound} the variance {vocalsound} of the es difference between the FFT spectrum and mel filter bank spectrum . professor e: Yeah . phd c: Uh , also the {disfmarker} another parameter is {disfmarker} relates with the auto - correlation function . professor e: Uh - huh . phd c: R - ze energy and the variance a also of the auto - correlation function . professor e: Uh - huh . So , that 's {disfmarker} Yeah . That 's what you were describing , I guess , a week or two ago . phd c: Yeah . But we don't have res we don't have result of the AURO for Aurora yet . professor e: So . phd c: We need to train the neural network professor e: Mm - hmm . phd c: and {disfmarker} professor e: So you 're training neural networks now ? phd c: No , not yet . professor e: So , what {disfmarker} wha {vocalsound} wh wha what what 's going on ? phd c: Well , we work in the report , too , because we have a lot of result , professor e: Uh - huh . phd c: they are very dispersed , and was necessary to {disfmarker} to look in all the directory to {disfmarker} to {disfmarker} to give some more structure . phd b: Yea professor e: So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens . phd c: Hm - hmm . phd b: Uh , y yeah . Basically we we 've stopped , uh , experimenting , professor e: Yes ? phd b: I mean . We 're just writing some kind of technical report . And {disfmarker} phd f: Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI , phd c: No . phd b: Yeah . phd c: For ICSI . phd f: or {disfmarker} ? Ah . I see . phd b: Yeah . phd c: Just summary of the experiment and the conclusion and something like that . professor e: Yeah . phd b: Mm - hmm . professor e: OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up . phd b: Mm - hmm . professor e: So that , you know {disfmarker} so that such a thing can be written . And , um {disfmarker} When {disfmarker} when {disfmarker} when do you leave again ? phd c: Uh , in July . First of July . professor e: First of July ? OK . And that you figure on actually finishing it in {disfmarker} in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway . phd b: Mm - hmm . phd c: Mm - hmm . professor e: And right now it 's kind of important that we actually go forward with experiments . phd c: It 's not . professor e: So {disfmarker} so , I {disfmarker} I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think {vocalsound} to {disfmarker} to really work on {disfmarker} on fine - tuning the report n at this point is {disfmarker} is probably bad timing , I {disfmarker} I {pause} think . phd b: Mm - hmm . Yeah . Well , we didn't {disfmarker} we just planned to work on it one week on this report , not {disfmarker} no more , anyway . Um . professor e: But you ma you may really wanna add other things later anyway phd b: Yeah . Mm - hmm . professor e: because you {disfmarker} phd b: Mmm . professor e: There 's more to go ? phd b: Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker} phd f: Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this , phd b: Uh . phd f: or {disfmarker} ? phd b: Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything . phd f: Mmm . phd b: But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um . professor e: That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ? phd b: Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector . phd c: Uh , for a v VAD . phd b: Right ? Um . phd f: Could you say it again ? What {disfmarker} what exactly did they do ? phd b: They used some parts of the , um , Italian database to train the voice activity detector , I think . It {disfmarker} professor e: Yeah . I guess the thing is {disfmarker} Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English {disfmarker} no , Italian and the Finnish and the English ? {disfmarker} were development data phd b: Yeah . And Spanish , yeah . professor e: on which you could adjust things . And the {disfmarker} and the German and Danish were the evaluation data . phd b: Mm - hmm . professor e: And then when they finally actually evaluated things they used everything . phd b: Yeah . That 's right . Uh {disfmarker} professor e: So {disfmarker} Uh , and it is true that the performance , uh , on the German was {disfmarker} I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good . phd b: Mm - hmm . professor e: So {disfmarker} And , uh , it {disfmarker} it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that {disfmarker} that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh {disfmarker} I mean they were different drives . phd b: Different cars . Yeah . professor e: I mean , it was {disfmarker} it was actual different cars and so on . phd b: Yeah . professor e: So . Um , it 's somewhat tuned . It 's tuned more than , you know , a {disfmarker} a {disfmarker} a {disfmarker} a {disfmarker} phd b: Mm - hmm . professor e: You 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most . phd b: Mm - hmm . professor e: But that 's not really what this contest is . So . Um , I guess it 's OK . phd b: Mm - hmm . professor e: That 's something I 'd like to understand before we actually use something from it , phd f: I think it 's {disfmarker} professor e: because it would {disfmarker} phd f: it 's probably something that , mmm , the {disfmarker} you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just {pause} doing signal - processing . phd b: Yeah . professor e: Well , it 's true , phd f: So . professor e: except that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that . phd f: Yeah . That 's true . professor e: Um . phd f: And they didn't forbid us {disfmarker} right ? {disfmarker} to build models on the data ? professor e: No . But , I think {disfmarker} I think that it {disfmarker} it {disfmarker} it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that {disfmarker} that it would look bad . And I think someone would notice and would say " Well , look . This is not generalizing . " I would hope tha I would hope they would . phd f: Mm - hmm . professor e: Um . But , uh , it 's true . You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other things . So it 's {disfmarker} it 's , uh {disfmarker} We should {disfmarker} we should {disfmarker} Maybe {disfmarker} that 's maybe a topic {disfmarker} Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek phd b: Mm - hmm . professor e: to , you know , double check it 's OK . phd f: Do we know anything about {pause} the speakers for each of the , uh , training utterances ? phd b: What do you mean ? We {disfmarker} we {disfmarker} phd f: Do you have speaker information ? professor e: Social security number phd f: That would be good . phd b: Like , we have {pause} male , female , phd c: Hmm . phd f: Bank PIN . phd b: at least . phd f: Just male f female ? phd b: Mmm . professor e: What kind of information do you mean ? phd f: Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization . phd b: Mm - hmm . phd f: Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of . phd b: Mm - hmm . professor e: Hmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're {vocalsound} supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure {disfmarker} I mean , having the two nets {disfmarker} Suppose you detected that it was male , it was female {disfmarker} you come up with different {disfmarker} phd f: Well , you could put them both in as separate streams or something . Uh . phd b: Mm - hmm . professor e: Maybe . phd f: I don't know . I was just wondering if there was other information we could exploit . phd b: Mm - hmm . professor e: Hmm . Yeah , it 's an interesting thought . Maybe having something along the {disfmarker} I mean , you can't really do vocal tract normalization . But something that had some of that effect phd f: Yeah . professor e: being applied to the data in some way . phd f: Mm - hmm . professor e: Um . phd b: Do you have something simple in mind for {disfmarker} I mean , vocal tract length normalization ? phd f: Uh no . I hadn't {disfmarker} I hadn't thought {disfmarker} it was {disfmarker} thought too much about it , really . It just {disfmarker} something that popped into my head just now . And so I {disfmarker} I {disfmarker} I mean , you could maybe use the ideas {disfmarker} a similar {pause} idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance {disfmarker} like , the likelihood of each utterance . You divide the {disfmarker} the range of the likelihoods up into discrete bins and then each bin 's got some knob {disfmarker} uh , setting . professor e: Yeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that {disfmarker} and where you 're not adjusting the statistical engine at all . phd f: Yeah . Yeah . phd b: Mm - hmm . phd f: Yeah . That 's true . professor e: You know , that just {disfmarker} phd f: Right . phd b: Hmm . professor e: I mean {disfmarker} Yeah . phd f: Could be expensive . professor e: No . Well not just expensive . I {disfmarker} I {disfmarker} I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only {disfmarker} Right ? phd f: Oh , professor e: Each frame comes in and it 's gotta go out the other end . phd f: right . professor e: So , uh {disfmarker} phd f: Right . So whatever it was , it would have to be uh sort of on a per frame basis . professor e: Yeah . phd b: Mm - hmm . professor e: Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff . phd f: Yeah . Yeah . professor e: But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker} phd f: I don't know . professor e: So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker} phd f: Mm - hmm . professor e: So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker} phd f: Mm - hmm . professor e: So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker} phd f: Hmm . professor e: But {disfmarker} Um , that doesn't work for just having one frame or something . phd f: Yeah . phd b: Mm - hmm . professor e: You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that , phd b: Mm - hmm . professor e: and {disfmarker} phd f: Right . professor e: Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum . phd f: Mm - hmm . professor e: So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um . phd f: Mm - hmm . professor e: But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ? phd f: Is it balanced , um , in terms of gender {disfmarker} the data ? phd b: Mmm . professor e: Do you know ? phd b: Almost , yeah . phd f: Hmm . phd b: Mm - hmm . professor e: Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ? phd b: Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou professor e: Shouldn't be . They should be less so . phd b: Yeah . But {disfmarker} professor e: R right ? phd b: Mmm . professor e: Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ? phd b: I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don professor e: Yeah . But you should always look at insertions , deletions , and substitutions . phd b: Yeah . Mm - hmm . professor e: So {disfmarker} phd b: Mm - hmm . professor e: so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them . phd b: Mm - hmm . professor e: So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features . phd b: Mm - hmm . professor e: So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum . phd b: Mm - hmm . Mm - hmm . professor e: And you might wanna change that . phd b: But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm . professor e: Yeah . phd b: Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input , professor e: Yeah . phd b: so I don Well . I don't know . professor e: That means they 're between zero and one . phd b: Mm - hmm . professor e: But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they could be , um {disfmarker} Do - doesn't tell you what the variance of the things is . phd b: Mmm . Mm - hmm . professor e: Right ? Cuz if you 're taking the log of these things , it could be , uh {disfmarker} Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are . phd b: Mm - hmm . Yeah . professor e: So . phd b: Yeah . So we should look at the likelihood , or {disfmarker} or what ? Or {disfmarker} well , at the log , perhaps , and {disfmarker} professor e: Yeah . Yeah . phd b: Mm - hmm . professor e: Or what {disfmarker} you know , what you 're uh {disfmarker} the thing you 're actually looking at . phd b: Mm - hmm . professor e: So your {disfmarker} your {disfmarker} the values that are {disfmarker} are actually being fed into HTK . phd b: Mm - hmm . But {disfmarker} professor e: What do they look like ? phd f: No And so th the , uh {disfmarker} for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ? phd b: Yes . professor e: Right . So they 're {pause} kinda like log probabilities is what I was saying . phd f: And those {disfmarker} OK . And tho that 's what goes {pause} into {pause} HTK ? professor e: Uh , almost . But then you actually do a KLT on them . phd f: OK . professor e: Um . They aren't normalized after that , are they ? phd b: Mmm . No , they are not {disfmarker} no . professor e: No . OK . So , um . Right . So the question is {disfmarker} Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is {disfmarker} is gonna be a good or a bad thing ? So . phd b: Mm - hmm . professor e: Uh , and that 's something that nothing {disfmarker} nothing else after that is gonna {disfmarker} Uh , things are gonna scale it {disfmarker} Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh {disfmarker} phd f: Yeah . Cuz if {disfmarker} if the log probs that are coming out of the MSG are really big , the standard {pause} insertion penalty is gonna have very little effect professor e: Well , the {disfmarker} Right . phd f: compared to , you know , a smaller set of log probs . professor e: Yeah . No . Again you don't really {pause} look at that . It 's something {disfmarker} that , and then it 's going through this transformation that 's probably pretty close to {disfmarker} It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a {disfmarker} a {disfmarker} a discrete cosine transformation is doing . phd f: Yeah . professor e: But still it 's {disfmarker} it 's not gonna probably radically change the scale of things . I would think . And , uh {disfmarker} Yeah . It may be entirely off and {disfmarker} and it may be {disfmarker} at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be {disfmarker} So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the {disfmarker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction . phd b: Mm - hmm . Mm - hmm . Yeah . But , professor e: Anything else ? phd b: my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work . professor e: Yeah . phd b: So . professor e: Well . phd b: And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker} professor e: Yeah . phd b: Mm - hmm . Yeah . Well . professor e: But , you know , some problems are harder than others , phd b: Mm - hmm . Yeah . professor e: and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know , phd b: Mm - hmm . professor e: so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ? phd b: Yeah . Yeah , sure . professor e: So . phd b: Uh . professor e: Hmm ? Yeah . phd b: Yeah . Well , there is also the spectral subtraction , which , um {disfmarker} I think maybe we should , uh , try to integrate it in {disfmarker} in our system . professor e: Yeah . phd b: Mmm . Mm - hmm . professor e: Right . phd b: But , professor e: O phd b: I think that would involve to {disfmarker} {vocalsound} to mmm {vocalsound} use a big {disfmarker} a {disfmarker} al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by , {vocalsound} um , other kind of processing that 's {disfmarker} are dependent on the {disfmarker} uh , if it 's speech or noi or silence . professor e: Mm - hmm . phd b: And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm . professor e: OK . Well , this 'll be , I think , something for discussion with Hynek next week . phd b: Yeah . Mm - hmm . professor e: Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ? grad d: Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here . professor e: Yeah . grad d: Do you know what his schedule will be like ? professor e: Uh , he 'll be around for three days . grad d: OK . So , y professor e: Uh , we 'll have a lot of time . grad d: OK . professor e: So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So . phd f: But you said you won't {disfmarker} you won't be here next Thursday ? professor e: Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat . phd f: Hmm . professor e: So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ? grad d: Mmm . Yeah . professor e: Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that 's {disfmarker} that 's one of the big advantages of not making much money is {vocalsound} the taxes are easier . Yeah . phd f: Unless you 're getting money in two countries . professor e: I think you are . Aren't you ? phd f: They both want their cut . phd b: Hmm . grad d: Hmm . Yeah . phd f: Right ? professor e: Yeah . Yeah . Huh . Canada w Canada wants a cut ? grad d: Mm - hmm . professor e: Have to do {disfmarker} So you {disfmarker} you have to do two returns ? grad d: Mmm . W uh , for two thousand I did . Yeah . professor e: Oh , oh . Yeah . For tw That 's right , ju phd f: But not for this next year ? professor e: Two thousand . Yeah . Probably not this next year , I guess . grad d: Ye professor e: Yeah . grad d: Um . professor e: Yeah . grad d: Uh , I 'll {disfmarker} I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a {disfmarker} considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return . professor e: OK . Alright . Uh . Barry , do you wanna {pause} say something about your stuff here ? grad a: Oh , um . Right . I {pause} just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um {disfmarker} Yeah . It 's {disfmarker} that 's pretty much it . professor e: Oh , well . No Um , why don't you say something about what it is ? grad a: Oh , you {disfmarker} oh , you want {disfmarker} you want details . Hmm . OK . professor e: Well , we 're all gathered here together . I thought we 'd , you know {disfmarker} grad a: I was hoping I could wave my hands . Um . So , um . So , once wa I {disfmarker} I was thinking getting {disfmarker} getting us a set of acoustic events to {disfmarker} um , to be able to distinguish between , uh , phones and words and stuff . And {vocalsound} um , once we {disfmarker} we would figure out a set of these events that can be , you know , um , hand - labeled or {disfmarker} or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um , {vocalsound} do some cheating experiments , um , where we feed , um , these events into {pause} an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah . grad d: Hey , Barry ? Can you give an example of an event ? grad a: Yeah . Sure . Um , I {disfmarker} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality . professor e: Whose paper is it ? grad a: Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen . professor e: Yeah . Huh . From , uh , University of Hamburg and Bielefeld . grad a: Mm - hmm . professor e: OK . grad a: Um . phd f: Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event . grad a: Mm - hmm . phd f: There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker} professor e: So , stuff that 's not based on data . phd f: Stuff that 's not based on data , necessarily . professor e: Yeah . Oh , OK . Yeah . Yeah , OK . phd f: Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height , grad a: Yeah . phd f: its tenseness , laxness , things like that , grad a: Mm - hmm . phd f: which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind . professor e: I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event . grad a: Good . That 's great . professor e: And , uh , um , called them " avents " , uh , uh , uh , with an A at the front . phd f: Mm - hmm . professor e: Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So . grad a: Mm - hmm . professor e: Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker} phd f: It 's kinda like the difference between top - down and bottom - up . professor e: Yeah . phd f: I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event . grad a: Mm - hmm . phd f: What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that . professor e: Mm - hmm . phd f: And so it 's sort of a different way of looking . professor e: Mm - hmm . grad a: Yeah . So . Yeah . grad d: OK . grad a: Mm - hmm . Um {disfmarker} Using these {disfmarker} these events , um , you know , we can {disfmarker} we can perform these {disfmarker} these , uh , cheating experiments . See how {disfmarker} how {disfmarker} how good they are , um , in , um {disfmarker} in terms of phoneme recognition or word recognition . And , um {disfmarker} and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this {disfmarker} this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um {disfmarker} to account for other {disfmarker} other phenomena like , um , CMR co - modulation release . And , um {disfmarker} and maybe also investigate ways to {disfmarker} to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff {disfmarker} Jeff , uh , Bilmes did his work . Um , and while I 'm {disfmarker} I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and {disfmarker} So {disfmarker} so , once we have these {disfmarker} these , uh , event detectors , um , we could put them together and {disfmarker} and feed the outputs of the event detectors into {disfmarker} into the SRI , um , HMM {disfmarker} HMM system , and , um {disfmarker} and test it on {disfmarker} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan . professor e: By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months . grad a: Mm - hmm . professor e: Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things . grad a: Hmm . professor e: So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disfmarker} are , uh , developing . grad a: Hmm . OK . professor e: So , he looks at interesting {disfmarker} interesting things in {disfmarker} in the {disfmarker} {vocalsound} different ways of looking at spectra in order to {disfmarker} to get various speech properties out . So . grad a: OK . professor e: OK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I {disfmarker} I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll {disfmarker} I 'll start . It 's , uh , one thirty - five . seventeen OK